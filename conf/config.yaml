debug: false
visualize: false

train:
  experiment_name: "drone_hovering"
  project_name: "DroneHoveringRL_v2"
  max_iterations: 500
  seed: 42
  num_steps_per_env: 24
  save_interval: 1000
  empirical_normalization: false
  runner_class_name: "OnPolicyRunner"
  policy:
    class_name: "ActorCritic"
    # class_name: "ActorCriticRecurrent"
    activation: "tanh"
    actor_hidden_dims: [128, 128]
    critic_hidden_dims: [128, 128]
    init_noise_std: 1.0
    # only needed for "ActorCriticRecurrent"
    rnn_type: "lstm"
    rnn_hidden_size: 512
    rnn_num_layers: 1
  algorithm:
    class_name: "PPO"
    clip_param: 0.2
    desired_kl: 0.01
    entropy_coef: 0.002
    gamma: 0.99
    lam: 0.95
    learning_rate: 0.0003
    max_grad_norm: 1.0
    num_learning_epochs: 5
    num_mini_batches: 4
    schedule: "adaptive"
    use_clipped_value_loss: true
    value_loss_coef: 1.0
    rnd_cfg: null
    symmetry_cfg: null

env:
  num_envs: 8192
  num_actions: 4
  termination_if_roll_greater_than: 180
  termination_if_pitch_greater_than: 180
  termination_if_close_to_ground: 0.1
  termination_if_x_greater_than: 3.0
  termination_if_y_greater_than: 3.0
  termination_if_z_greater_than: 2.0
  base_init_pos: [0.0, 0.0, 1.0]
  base_init_quat: [1.0, 0.0, 0.0, 0.0]
  episode_length_s: 15.0
  hover_duration_s: 0.5
  at_target_threshold: 0.1
  resampling_time_s: 3.0
  simulate_action_latency: true
  clip_actions: 1.0
  visualize_target: false
  visualize_camera: false
  max_visualize_FPS: 60

obs:
  num_obs: 17
  obs_scales:
    rel_pos: 0.3333333333333333  # 1/3.0 の値
    lin_vel: 0.3333333333333333
    ang_vel: 0.3183108861837907  # 1/3.14159 の近似値

reward:
  yaw_lambda: -10.0
  reward_scales:
    target: 10.0
    smooth: -1e-4
    yaw: 0.01
    angular: -2e-4
    crash: -10.0
    hover: 0.1
    altitude: 1.0

command:
  num_commands: 3
  pos_x_range: [-1.0, 1.0]
  pos_y_range: [-1.0, 1.0]
  pos_z_range: [1.0, 1.0]
  seed: 42